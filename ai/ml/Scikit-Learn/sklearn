#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚£¶‚£¥‚£∂‚£æ‚£ø‚£∂‚£∂‚£∂‚£∂‚£¶‚£§‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä                                              
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚°∂‚†ª‚†õ‚†ü‚†ã‚†â‚†Ä‚†à‚†§‚†¥‚†∂‚†∂‚¢æ‚£ø‚£ø‚£ø‚£∑‚£¶‚†Ñ‚†Ä‚†Ä‚†Ä                 ìêì  sklearn ìêî           
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†î‚†ã‚†Ä‚†Ä‚†§‚†í‚†í‚¢≤‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚£§‚£§‚£¨‚£Ω‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†Ä‚†Ä                                              
#  ‚†Ä‚†Ä‚†Ä‚£Ä‚£é‚¢§‚£∂‚£æ‚†Ö‚†Ä‚†Ä‚¢Ä‚°§‚†è‚†Ä‚†Ä‚†Ä‚††‚£Ñ‚£à‚°ô‚†ª‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£¶‚†Ä       Dev: oezzaou <OussamaEzzaou@gmail.com> 
#  ‚¢Ä‚†î‚†â‚†Ä‚†ä‚†ø‚†ø‚£ø‚†Ç‚††‚†¢‚£§‚†§‚£§‚£º‚£ø‚£∂‚£∂‚£§‚£ù‚£ª‚£∑‚£¶‚£ç‚°ª‚£ø‚£ø‚£ø‚£ø‚°Ä                                              
#  ‚¢æ‚£æ‚£Ü‚£§‚£§‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚¢ª‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á                                              
#  ‚†Ä‚†à‚¢ã‚¢π‚†ã‚†â‚†ô‚¢¶‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£º‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á       Created: 2025/07/23 16:21:13 by oezzaou
#  ‚†Ä‚†Ä‚†Ä‚†ë‚†Ä‚†Ä‚†Ä‚†à‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†á       Updated: 2025/08/01 17:36:56 by oezzaou
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚¢Ä‚£æ‚£ø‚£ø‚†ø‚†ü‚†õ‚†ã‚†õ‚¢ø‚£ø‚£ø‚†ª‚£ø‚£ø‚£ø‚£ø‚°ø‚†Ä                                              
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†á‚†Ä‚¢†‚£ø‚£ü‚£≠‚£§‚£∂‚£¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†à‚†ª‚†Ä‚†ò‚£ø‚£ø‚£ø‚†á‚†Ä                                              
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†±‚†§‚†ä‚†Ä‚¢Ä‚£ø‚°ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚£ø‚†è‚†Ä‚†Ä                             ìÜ©‚ôïìÜ™      
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ñ‚†Ä‚†Ä‚†Ä‚†ò‚¢ß‚°Ä‚†Ä‚†Ä‚†∏‚£ø‚£ø‚£ø‚†ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ê‚†ã‚†Ä‚†Ä‚†Ä                     ìÑÇ oussama ezzaouìÜÉ  
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚†Ñ‚£Ä‚°Ä‚†∏‚†ì‚†Ä‚†Ä‚†Ä‚††‚†ü‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä                                              

===[ Index: ]===================================================================
1|> Sickit-Learn 
    - sklearn datasets
    - Input Features and Target Labels 
2|> Sklearn Models
    - Model Interfaces (Inconsistent APIs)
    - Models Categories
    - Supervised Learning Models 
      . Regression (linear_model models, tree models)
      . Classification
    - Unsupervisde learning Models
3|> Preprocessing
4|> Metrices 
5|> Meta Estimators 
6|> Human-Learn

===[ Sickit-Learn: ]============================================================
* Now that you are confortable with 'NumPy/Pandas' for data manipulation and
  'MatPlotLib/Seaborn', You are ready to dive into the next big step in the 
  'datascience pipline': 'machine learning and (scikit-learn)' 
  # NOTE:> scikit-learn (often abbreviated as 'sklearn')
  - Sickit-learn is a powerful, easy-to-use Python library for 'machine'
    'learning' It has been built on the top for core python libraries like:
    > 'NumPy': (for numerical operations)
    > 'SciPy': (for scientific computing) 
    > 'matplotlib' (for basic visualization)
  - It provides 'simple and efficient tools' for predictive data analysis,
    supporting, supporting both 'supervised' and 'unsupervised learning' 
    along with tools for:
    > 'preprocessing'
    > 'Model Selection'
    > 'evaluation'
  
  # QUESTION:[ Where does scikit-learn fit in the data Science live Cycle? ]===
  # 1|> Data Collection 
  # 2|> Data Cleaning (NumPy/Pandas)
  #     - remove duplicates
  #     - handle missing (drop nans, or imputation, mean, bfill, ffill, etc>) 
  #     - Correct Inconsisting formats ()
  # 3|> Exploratry Data Analysis (EDA)  
  #     - Data Visualization (matplotlib/Seaborn) 
  #     - Data Analysis
  #       . Summary statistics (df.describe(), df.info())
  #       . Understand relationships, distributions, correlations
  # 4|> Preprocessing (scikit-learn starts here) 
  #     - data Transformation (Feature Scaling & categorical Encoding) 
  #     - Feature Engineering
  # 5|> Modeling
  #     - Select ML algorithm (linearReression)
  #     - Train Model: model.fit()
  #     - Predict: model.predict()
  #     - Evaluate

===[ Sklearn: Datasets ]===
* Scikit-learn provides a collection of 'datasets' that are useful for 
  'practicing machine learning' without having to search for or prepare data.
  - These datasets are available via 'sklearn.datasets'.

# REVISION:---------------------------------------------------------------------
# - Seaborn is also used to load built-in datasets: 
#   > seaborn.get_dataset_names() => To get all available built-in datasets
#   > seaborn.load_dataset(name)  => To load the a specific dataset from list 

      |---------------[ Dataset Types in `Sklearn` ]------------------| 
      |                               |                               |
  [ Toy Datasets ]      [ Real-World Datasets ]       [ Synthetic Datasets ]
* Small and built-in    * They are slightly         * Scikit-learn allows you
> (Built-in)              larger datasets             to generate data to test
                          that are 'fetched'          specific algorithms
                          'from the internet'       > (Generated)
                          and my be cached
                          locally.
                        > (Featched/Downloaded)

1|> [ Toy Datasets: (Built-in) ]
    - These are loaded directly into memory and are very fast to access.
    ____________________________________________________________________________
    Function               | Description                      | Target Type    |
    -----------------------|----------------------------------|----------------|
    `load_iris()`          | Iris flower (3 classes)          | Classification |
    `load_digits()`        | Handwritten digits (0‚Äì9)         | Classification |
    `load_wine()`          | Wine characteristics (3 types)   | Classification |
    `load_breast_cancer()` | Breast cancer (malignant/benign) | Classification |
    `load_diabetes()`      | Diabetes disease progression     | Regression     |
    _______________________|__________________________________|________________|
    # NOTE:---------------------------------------------
    # - These return a 'Bunch object' like a dictionary.

2|> [ Real Datasets: (Fetched/Downloaded) ] 
    - These are slightly larger datasets that are 'fetched from the internet'
      and may be cached locally.
    ____________________________________________________________________________
    Function                    | Description                    | Target Type |
    ----------------------------|--------------------------------|-------------|
    `fetch_california_housing()`|-House prices in California     | Regre       |
    `fetch_20newsgroups()`      |-Newsgroup text classification  | Class       |
    `fetch_olivetti_faces()`    |-Faces images (64x64 grayscale) | Class       |
    `fetch_covtype()`           |-Forest cover types from        | Class       |
                                | cartographic data              |             |
    `fetch_lfw_people()`        |-Labeled Faces in the Wild      | Class       |
                                | (face recognition)             |             |
    ____________________________|________________________________|_____________|
    # NOTE:-------------------------------------------------
    # - These functions typically include: 
    #   > `as_frame=True` (for returning a Pandas DataFrame)
    #   > `download_if_missing=True`

3|> [ Synthetic Datasets: (Generated) ]
    - Scikit-learn allows you to generate data to test specific algorithms.
    _______________________________________________________________________
    | Function                           | Description                    |
    |------------------------------------|--------------------------------|
    |-`make_classification()`            |-Random classification dataset  |
    |-`make_regression()`                |-Random regression dataset      |
    |-`make_blobs()`                     |-Gaussian blobs (clustering)    |
    |-`make_moons()`                     |-Binary classification with     |
    |                                    | moon shapes                    |
    |-`make_circles()`                   |-Binary classification with     | 
    |                                    | circular shapes                |
    |-`make_multilabel_classification()` |-Multi-label classification     |
    |____________________________________|________________________________|

# INFO:[ Dataset Object Structure: `Bunch` ]====================================
# - Most datasets return a 'Bunch object' which behaves like a dictionary and 
#   typically includes:
#   {
#     'data': X,               # Features
#     'target': y,             # Labels
#     'feature_names': [...],  # Feature column names
#     'target_names': [...],   # Class names (for classification)
#     'DESCR': "...",          # Description text
#   }
# INFO:[ Summary: ]-------------------------------------------------------------
#   ____________________________________________________________________________
#   | Type      | Examples                   | Purpose                         |
#   |-----------|----------------------------|---------------------------------|
#   | Toy       | `load_iris`, `load_wine`   | Quick demos, learning concepts  |
#   | Real      | `fetch_california_housing` | Real-world data, larger scale   |
#   | Synthetic | `make_classification`      | Testing algorithms,             |
#   |           |                            | experimentation                 |
#   |___________|____________________________|_________________________________|
# ==============================================================================

===[ Sklearn: Input Feature ('X') & Target Labels ('Y') ]===
* 'X' represents the 'input features' 'Independent Variables', They are used
  to make 'predictions'.
* 'Y' represents the 'target label', 'Dependent Variable', The are predection
  that i am interested in making.

  > [ Exmaple (1): Kaggle - Titanic Dataset ]
    'X': Sex, Port, Price, Ticket, ... 
    'Y': Survived

  > [ Exmaple (2): sklearn datasets ]
    1. Toy/Built-in datasets => returns a 'Bunch' Object where:
       - 'X': Input features: 'bunch.data' 
       - 'Y': Target label:   'bunch.label' 

    2. Real-World/Fetched datasets => returns a 'Bunch' Object where:
       - 'X': Input features: 'bunch.data' 
       - 'Y': Target label:   'bunch.label' 

    3. Generated datasets => retuns a 'Tuple (data, label)' object where:
       - 'X': Input features: 'tuple[0]'
       - 'Y': Target label:   'tuple[1]'

===[ sklearn: Models ]==========================================================
* A 'Model' is 'machine learning algorithm' that is used to learn patterns from
  data.
  - A 'Model' is an 'object' that can be:
    > 'trained (fit)' on data
    > used to 'make predictions' on new data
    > Follow a 'consistent API' using methods like `.fit()`, `.predict()`,
      `.score()`, etc

  # QUESTION:[ does 'consistent API' mean that these functions 
  #                                                   operates over network ]===
  # - When we say that Scikit-learn has a 'consistent API', we are not referring
  #   to 'web APIs' or 'network communication', Instead we mean that all models
  #   follow the same 'interface' (They inherite from the same abstracted class)
  #   => A consistent 'Application Programming Interface in Python'
  # >>> This Interface is defined by 'abstract base classes' like 
  #   - `BaseEstimator`
  #   - `RegressorMixin`
  #   - `ClassifierMixin`
  #   - `TransformerMixin`
  # NOTE:----------------------------------------------------------------------- 
  # - When we say fit()/predict() are part of Scikit-learn‚Äôs API, we mean
  #   interface, not network. The model is trained and used locally.

===[ sklearn: Model Interfaces ('consistent APIs') ]===

- This is a Summary Diagram of the 'common interfaces' used between sklearn 
  'Models'.
            
                        +----------------+
                        |  Estimator     |  
                        |----------------|
                        | `BaseEstimator`|
                        | + fit()        |
                        | + get_params() |
                        | + set_params() |
                        +-------+--------+
                                |
          +---------------------+---------------+
          |                                     |
    `RegressorMixin`                      `TransformerMixin`
    +-------v------+                 +-----------v----------+
    | Predictor    |                 | Transformer          |
    |--------------|                 |----------------------|
    |+ predict(X)  |                 |+ fit()               |
    |+ score(X, y) |                 |+ transform()         |
    +--------------+                 |+ fit_transform()     |
          |                          |+ inverse_transform() |
    `ClassifierMixin`                +----------------------+
  +-----------v----------+         
  | Classifier           |
  |----------------------|
  |+ predict_proba(X)    |
  |+ predict_log_proba(X)|
  |+ decision_functions(X)
  | (predict_proba)      |
  +----------------------+

  >>> 'All Models' are 'Estimators', But Models, that implement 'Both' `fit()` 
      and `predict()` are called 'Predictors'.
      # NOTE:[ VERY IMPORTNAT ]=================================================
      # >>> Estimator & Predictor are the 'Core Concept of Models'.            | 
      # ========================================================================
  >>> As you can see all Scikit-learn models implement `BaseEstimator` Interface

# INFO:[ SUMMARY ]==============================================================
# * scikit-learn's architecture is designed around this:                       | 
#   - All ML components (models, scalters, imputers, reducers) are "Estimators"|
#   - Some are also "Predictors", some are also "Transformers".                |
# _____________________________________________________________________________|
# | Interface     | Core Method(s)            | Purpose                        |
# |---------------|---------------------------|--------------------------------|
# | `Estimator`   | `.fit(X, y)` or `.fit(X)` | Learns from data               |
# | `Predictor`   | `.predict(X)`             | Makes predictions              |
# | `Transformer` | `.transform(X)`           | Transforms input (e.g.,        |
# |               |                           | scaling, PCA)                  |
# ==============================================================================

===[ sklearn: Model Categories ]===
* sklearn models are categorized to:

              |------------[ Model Categories ]-------------|
              |                                             |
  [ Supervised Learnin Models ]               [ Unsupervised Learnin Models ]
              |                                             |
      |-------|---------|                         |---------|----------|
      |                 |                         |                    |
[ Regression ]      [ Classification ]    [ Clustering ]    [ Dimens Reduction ] 


===[ sklearn: Supervised Learning Models ]===
* Supervisde learning models learn from 'labled data', It is a data that has
  'target inputs'.
  # NOTE:[ IMPORTANT ]----------------------------------------------------------
  # - All supervised models in Scikit-learn are both 'Estimators' & 'Predictors'
  # - Unsupervised learning models are typically 'Estimators', and optionally
  #   'Transformers' or 'Predictors', depending on what they do. 

>>> [ Regression Models: (Predict continuous values) ]
    # REVISION:-----------------------------------------------------------------
    # - Regression Models try to find a 'relationship' between 'input features'
    #   (X) and 'target label' (y)
    # - The model learns this relationship by minimizing a loss 'function',
    #   commonly the 'Mean Squared Error (MSE)' (minimizing cost function Ja->,b)
    # - Once trained, The model can 'predict values for unseen data'.

    - All 'regression models' implement the 'RegressorMixin interface'. 
    - `RegressorMixin` is a 'mixin class' provided by `sklearn.base` that
      adds interface to 'all regression estimators', It provides: 
      . `.score(X, y)` method: Return 'R^2 score' (coefficient of
        determination) which measures how well the model predicts the target
        
      [ from sklearn.base import RegressorMixin ]

    # QUESTION:[ Does `RegressorMixin` inherite from `BaseEstimator`? ]=========
    # - `RegressorMixin` does not inherite from 'BaseEstimator', They are 
    #   'separate mixins', However, 'all scikit-learn regressors' typically 
    #   'inherit from BOTH'

  1|> [ Linear Models: ]
    ____________________________________________________________________________
    | Model Name          | Class Name          | Description                  |
    |---------------------|---------------------|------------------------------|
    | Linear Regression   | `LinearRegression`  | OLS linear regression        |
    | Ridge Regression    | `Ridge`             | L2 regularization            |
    | Lasso Regression    | `Lasso`             | L1 regularization            |
    |                     |                     | (sparse models)              |
    | ElasticNet          | `ElasticNet`        | L1 + L2 combined             |
    |---------------------|---------------------|------------------------------|

    # INFO:----------------------------------------------------------
    # >> These models are part from `sklearn.linear_model` module.  
    # NOTE:----------------------------------------------------------
    # - The list above contains the most important models only 
    # - here is the list of the others: 
    # _______________________________________________________________
    # | Class Name          | Description                           |
    # |---------------------|---------------------------------------|
    # | `BayesianRidge`     | Probabilistic linear regression       |
    # | `ARDRegression`     | Automatic Relevance Determination     |
    # | `HuberRegressor`    | Robust to outliers                    |
    # | `TheilSenRegressor` | Robust to multicollinearity           |
    # | `RANSACRegressor`   | Robust to large number of outliers    |
    # | `QuantileRegressor` | Predicts quantiles                    |
    # | `TweedieRegressor`  | For generalized linear models         |
    # | `PoissonRegressor`  | Poisson-distributed target (counts)   |
    # | `GammaRegressor`    | For skewed continuous positive values |
    # | `SGDRegressor`      | Linear model trained with SGD         |
    # |_____________________|_______________________________________|

    2|> [ Tree-Based Models: ]
      __________________________________________________________________________
      | Model Name           | Class Name                                      |
      |----------------------|-------------------------------------------------|
      | Decision Tree        | `DecisionTreeRegressor`                         |
      | Random Forest        | `RandomForestRegressor`                         |
      |----------------------|-------------------------------------------------|
      | Extra Trees          | `ExtraTreesRegressor`                           |
      | Gradient Boosting    | `GradientBoostingRegressor`                     |
      | HistGradientBoosting | `HistGradientBoostingRegressor` (for large data)|
      |______________________|_________________________________________________|

      # INFO:-------------------------------------------------------------------
      # >> These models are part from `sklearn.tree` module.  

===[ sklearn: Unsupervised Learning Models ]===

===[ sklearn: Preprocessing ]===================================================
