#  ⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣤⣦⣴⣶⣾⣿⣶⣶⣶⣶⣦⣤⣄⠀⠀⠀⠀⠀⠀⠀                                              
#  ⠀⠀⠀⠀⠀⠀⠀⢠⡶⠻⠛⠟⠋⠉⠀⠈⠤⠴⠶⠶⢾⣿⣿⣿⣷⣦⠄⠀⠀⠀                𓐓  ML_model 𓐔           
#  ⠀⠀⠀⠀⠀⢀⠔⠋⠀⠀⠤⠒⠒⢲⠀⠀⠀⢀⣠⣤⣤⣬⣽⣿⣿⣿⣷⣄⠀⠀                                              
#  ⠀⠀⠀⣀⣎⢤⣶⣾⠅⠀⠀⢀⡤⠏⠀⠀⠀⠠⣄⣈⡙⠻⢿⣿⣿⣿⣿⣿⣦⠀       Dev:  oezzaou  oussama.ezzaou@gmail.com 
#  ⢀⠔⠉⠀⠊⠿⠿⣿⠂⠠⠢⣤⠤⣤⣼⣿⣶⣶⣤⣝⣻⣷⣦⣍⡻⣿⣿⣿⣿⡀                                              
#  ⢾⣾⣆⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠉⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇                                              
#  ⠀⠈⢋⢹⠋⠉⠙⢦⠀⠀⠀⠀⠀⠀⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇       Created: 2025/05/12 08:13:45 by oezzaou
#  ⠀⠀⠀⠑⠀⠀⠀⠈⡇⠀⠀⠀⠀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠇       Updated: 2025/07/24 13:07:42 by oezzaou
#  ⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⢀⣾⣿⣿⠿⠟⠛⠋⠛⢿⣿⣿⠻⣿⣿⣿⣿⡿⠀                                              
#  ⠀⠀⠀⠀⠀⠀⠀⢀⠇⠀⢠⣿⣟⣭⣤⣶⣦⣄⡀⠀⠀⠈⠻⠀⠘⣿⣿⣿⠇⠀                                              
#  ⠀⠀⠀⠀⠀⠱⠤⠊⠀⢀⣿⡿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠘⣿⠏⠀⠀                             𓆩♕𓆪      
#  ⠀⠀⠀⠀⠀⡄⠀⠀⠀⠘⢧⡀⠀⠀⠸⣿⣿⣿⠟⠀⠀⠀⠀⠀⠀⠐⠋⠀⠀⠀                     𓄂 oussama ezzaou𓆃  
#  ⠀⠀⠀⠀⠀⠘⠄⣀⡀⠸⠓⠀⠀⠀⠠⠟⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀                                              

===[ Index: ]===================================================================
1|> Linear Regression
    - cost function (Squared Error Cost function)
    - Gradient Descent 
2|> Multiple Linear Regression
    - Feature Scaling (range (min_max), z-score, robust)
    - checking gradient descent for convertions (learning curve & learning rate)
3|> Plynomial Regression 
    - Feature Engineering
4|> Regression VS Classification
5|> Logistic Regression
    - Decision Boundary 
    - Cost function 
6|> Overfitting & Underfitting
    - overfitting
      . Regularization 
      . Cost function with regularization
      . Gradient Descent with regularization

===[ Model: Linear Regression ]=================================================
* Linear regression: (easy) is used to 'model the relationship' between: 
  - One independent variable (push_swap: Size)
  - One dependent variable (push_swap: Range)
    > It fits a 'stright' line through the 'data that best predict the output'.

  > [ Model Formula: ]

      f(x) = ax + b

    - The formula is called 'model' also in ML.
    - f(x): (y) is the target (y-hat is the estimated/predicted value)
    - x: Input feature 

    # NOTE:=====================================================================
    # - Training set is the data used for training the model.                  |
    # - The generted fuction is called sometimes 'hypothesis'.                 |
    # ==========================================================================

  > [ Example: ]
    - Predection of salary based on the experionce:
    _______________________________
    | Experience (x) | Salary (y) |
    |----------------|------------|
    | 1              |  30k       |
    | 2              |  35k       |
    | 3              |  40k       |
    |_4______________|__45k_______|

    * The model my learn: 

      Salary = 5000 * Experience + 25000 

    * if input feature = 5
      Salary predected = 500 * 5 + 25000 = 50000

    > [ What it does ?: ]
      - It taks a data set of (x, y) data points.
      - Find the 'line for the function that minimize the error' between
        'predicted and actual value'.
      - After training it can predict a 'y-hat' for any input feature 'x' 

# TIP:========================================================================== 
# - Curve function gives sometimes more predictive input (The same case that   |
#   i have faced) in push swap Where a I got a curve function between size     |
#   and range and i have choosen to work with linear function instead to       |
#   simplify the calculation.                                                  |
# - Improving means find the function (model) that gives target inputs (y-hat) |
#   'predective output' closer to the 'actual output'.                         | 
# - Improving the model involves changing the value of 'a (slop)' and          | 
#   'b y-intercept'. That is the same what i have done to improve my function  |
#   in push_swap (a, b: are called parametters/coefficients/weights).          |
# - But how can we measure and make sure that the optimized function is the    |
#   suitable one ? (cost function).                                            | 
# ==============================================================================

===[ Cost Function: Squared error cost function ]===
  - In machine learning a cost function is 'mathematical formula' that measures
    how wrong model's prediction are. It simply tells the model how 'far off'
    from the true value (it measures the quality of fiting).
      * Low Cost: good predictions
      * High Cost: bad predictions

      (MSE): stands for Mean Squared Error
               |-----------------------------------------------------|
      Formula: | J(a, b) = 1 / 2n * sum (i -> n) (Ypi - Yai)^2       |
               |-----------------------------------------------------|

      # TIP: DO NOT forget to prove it mathimaticaly. 

      - Yai: is the actual/True output at 'i' 
      - Ypi: is the predictive output estemated by the model at 'i'. 
      - (Ypi - Yai) is called the 'error' or 'residual', distance
        between [actual/True output, predictive output], residual can
        be 'positive/negative'.
      - n: number of trained examples. 

# QUESTION:[ Why devided by 2n ?]=============================================== 
# - Dividing 'n' gives the **average** squared error across all training       |
#   examples truning it into a [ mean squared error ].                         |
# - Dividing by '2' is done for 'mathematical convenience', when you perform   |
#   'gradient descent' to minimize the cost function, you will compute its     |
#   derivative, The derivative of a squared term (e.g., (h − y)^2) brings      |
#   down a factor of 2, which cancels out with the 1 / 2, 'This simplifies the |
#   gradient update formula'.                                                  | 
# CONCLUSION:                                                                  |
# - 1/n → Makes the cost function an average per training example.             |
# - 1/2 → Simplifies the math when taking derivatives.                         |
# ==============================================================================

===[ Gradient Descent: ]===
* This algorithm is used to find the lowest point in the function. There are
  a lot of algorithms used to find the lowest point.

  1|_ find the solution of the equation f'(x) = 0 (where the slop at Xl is 0) 
  2|_ descent algorithm
  3|_ ...

- The cost function depends on the linear regression function, which depends on
  the slop (a) and y-intercept (b) => Cost function depends on the slop and
  y-intercept.

       J(a, b) = 1/2n sum(1 -> n) (Yp - Ya)^2 

    => [ J(a, b) = 1/2n sum(1 ->n) (ax + b - Ya)^2 ]

- J(a, b) is a multi-variable function, We will use the partial dirivative to
  track the rate of change (slop of J(a,b) at in respect of 'a' or 'b').
  > Initial derivative of J(a, b) in respect of a | range of change cost J(a,b)
    according to slop (a). 
  > Initial derivative of J(a, b) in repsect of b | range of change cost J(a,b)
    according to y-intercept (b).

# INFO:[ Descent Gradient Analogy ]=============================================
# - It is like moving blind you just make a small step and feel the steepness  |
#   then you move on.                                                          |
# ==============================================================================
- let's take a = 0 and b = 0

  1|> Solution:
    - we need to find the dirivative on 'a' and dirivative on 'b'. 
    - Let's take a random point in the graph the slop(a) and cost function(a,b)

        J(a,b)
          |
          |                   /
          |                  /
          |___________ /\   /
          |           /| \_/
          |          / |
          |         /  |
          |------------|-----------> (a)
                    <- Ai ->

  1|> The idea is to choose a point 'slop a(i)' as an initial value. 
  2|> Partial derivative gives me the 'rate of change' at a specific '(ai)'
  3|> Start moving by a step 'alpha' based on this form: 

     /|-> A(new) = A(i) - alpha * change of range at point A(i) 
  --||
     \|-> B(new) = B(i) - alpha * change of rate at point B(i)
    
     /|-> A(new) = A(i) - LR * (Partial Dirived at A(i) Point)  
  --||
     \|-> B(new) = A(i) - LR * (Partial Dirived at B(i) Point)

     /|-> A(new) = A(i) - LR * &/&x J(a,b)  
  --||
     \|-> B(new) = A(i) - LR * &/&y J(a,b)

     /|-> A(new) = A(i) - LR *  &/&x (sum(i=0->m) (Y-hat(i) - Ya)^2 / 2m)
  --||
     \|-> B(new) = A(i) - LR * &/&y (sum(i=0->m) (Y-hat(i) - Ya)^2 / 2m)

     /|-> A(new) = A(i) - LR *  (sum(i=0->m) (Y-hat(xi) - Ya)^2 / m) * xi
  --||
     \|-> B(new) = A(i) - LR * (sum(i=0->m) (Y-hat(xi) - Ya)^2 / m)


# INFO:=========================================================================
# - What we do exactly here is to move on the x Axis to find the point that has|
#   the partial dirivative at xi = 6xi/6x|/6yi/6y = slop = 0.                  |
# CONCLUSION:===================================================================
# - The gradient descent algorithm is about finding the min of the function    |
#   min(f(x)) where the slop is 0 (It is one of the most poplular algorithms). |
# ==============================================================================

- When you use all the training data to calculate the min(J(w,b)), In simple
  term using all training data at each step of gradient descent is called 
  'batch gradient descent'.

# QUESTION:[Why gradient descent for the best fitting instead of Pearons's (r) ]
# - Pearson’s r is useful for interpreting simple linear relationships,
#   but gradient descent is a flexible optimization tool for learning the best
#   parameters in more complex and high-dimensional models, which is essential
#   in modern machine learning.
# - But you can still use Pearson's r cofficient in the case of simple linear 
#   regression to find the equation of the best line that fits the data.

===[ Model: Multiple linear regression ]========================================
* This model is used to model the relationship between one 'dependent' variable
  and 'two or more independent variables'|also called 'predictors' or 'features'

  > [ model formula: ]
      - single linear regression formula is:
        f(x) = ax + b
      - multiple linear regression formula would look like: 
        f(x, y, ....) = ax + by + cz ... + b
        f(x1, x2, x3 ...) = a1 * x1 + a2 * x2 + ... + an * xn + b
      
      . moving a unit on x
      . moving b unit on y
      . moving c unit on z
        ...

      x-> = |x| = |x1|         a-> = |a| = |a1| 
            |y|   |x2|               |b|   |a2|
            |z|   |x3|               |c|   |a3|
            ...   ...                   ...    ...
      
      # NOTE: a-> is a row vector while x-> is a column vector. 

        [ f(x->) = a-> . x-> + b ] 

  # NOTE: a-> . x-> : is called dot product, It is the projection of a-> on x->
  # ERROR:
  # - what i have said is not true at all 
  # - row vector is not a ghraphical vector, i guess no projection is here. 

===[ Feature Scaling: ]===
    * Feature scaling is 'preprocessing technique' used to 'normalize' the 
      range of independent variables (features) in a dataset

    - Normalization (min-max scaling), Standardization (Z-score Scaling) are a
      'common methods of feature scaling'. 

    # NOTE:=====================================================================
    # - Instead of working by the original values, we can work by normalization,
    #   standerdization forms Instead. but Why ?
    # - To keep the input feature values in the same range, (their ranges must
    #   be close to each others) 
    # - Of course there is nothing can make this transformation than
    #   Normalization (max, mean ...), Standardization (Z-score ...), ... 

  # INFO:
   - The Z-score normalization or standardization is the most method famous
     method to make 'feature scaling'.

  > [ Feature Transformation methods: ]

  |--------------------------------[ Normalization ]-------------------------|
  |                                       |                                  | 
[ range normalization ]         [  Z-score normalization   ]  [ Robust Scaling ] 
|- Math concept name: 'affine'  |- Math concept: 'standard'   |-Base on 'median' 
|  'transformation'.            |  'score transformation'     | and 'IQR', this
|- It maps data from its        |- It 'centers' the data      | technique is 
|  'original' range to 'new'    |  (mean = 0) and scales      | more 'resistant'
|  'range' usually '[0, 1]'     |  it to unit variance        | to 'outliers'
|  using a 'linear'             |  (std=1)                    |
|  'transformation'             |- Formula:                   |- Formula
|- Formula:                     |       X - mean              |      x - Median 
|         X - Xmin              | X' = ----------             | X' = ----------
|  X'  = ----------             |       std (&)               |         IQR 
|        Xmax - Xmin            |- std: average distance      |- Ref : 'Median'
|- Reference: 'Range'           |  of each x from the mean    | 
|                               |- 'sensetive' to 'outliers'  | 
|                               |- reference: 'Mean'          | 

  # QUESTION:[ When to use feature scaling ? ]==================================
  # - range: (-1 => 1), (-3 => 3), (-0.3 => 0.3) are acceptable ranges.
  #   |=> (no need for scaling) 
  # - range: (0 => 3), (-2 => 0.5): it's okey, can be rescaled also 
  # - range: (-100 => 100) too large => rescale 
  # - range: (-0.001 => 0.001) too small => rescale
  # ============================================================================

  # CONCLUSION:=================================================================
  # - Achno hiya Feature Transformation or scaling hiya bi basata tanrakeb
  #   wahed l mask li kol value, mask howa value wehda akhra li katmatel nafss
  #   l quentity fi range or scale wahed akhur swa kbar mno o la sghar mno.
  # ============================================================================

===[ Checking gradient Descent for Conversion ]===

  > [ Learning Curve: ]

# REVISION:=====================================================================
# - Gradient Descent algorithm is a method to find the min of cost function
#   (global minimum). 
#   J(a,b)
#
#   | A(new) = A(old) - LR * & J(a,b) / &A 
# =>|
#   | B(new) = B(old) - LR * & J(a,b) / &B 
#
# - We keep iterating (making steps) until conversion where A = Cste & B = Cste
# ==============================================================================

- 'Based on the revision', we know that the 'cost function' changes at each 
  'iteration (step)' made using gradient descent algorithm, So let's represent 
  'the changing of cost by number of iterations' in scatter plot

J(a->, b)
  |
  | *
  | *
  | *
  |  *
  |   *
  |     *
  |       *
  |          * *   *   *
  |---------------------------------> Iterations

  - This curve is called 'Learning Curve', In this case Gradient descent is
    'working correctly'

> [ Examples: Case of divertion ]

J(a->, b)                                J(a->, b)
  |                                          |
  |                                          |                     * 
  |                                          |                    * 
  | *                                        |                   *
  |  *        *     * *                      |                 * 
  |   *      * *   *   *                     |               *
  |     *   *   * *      *    *              |             *
  |       *                *                 |          *
  |                                          | *  *  * 
  |---------------------------> Iters        |---------------------------> Iters
  - Learning rate is big or there is a       - learing rate is big but the most 
    problem in the code.                       famous problem in this case 
                                               the code.

  # NOTE:=======================================================================
  # - This is the graphical method to check if the gradient descent is
  #   working properly. 
  # - There is another method called Automatic covergence test.
  # ============================================================================
  
  > [ Automatic convergence test ]
    * Is a constant value 'epsilon'

      [ epsilon = 10^-3 = 0.001 ] 

    - If J(a->, b) decreases by <= epsilon in one iteration, declare
      'convergence'

  # NOTE:=======================================================================
  # - The learning curve is the best method to check for gradient descent if
  #   it is working properly. 
  # ============================================================================

  >  [ How to find the best Learning Rate: ]===
     * Keep changing the 'learning rate' and visualize the 'learning curve'    

     - It is globaly known to start by: 

        Learning Rate = 0.001     | 
        Learing Rate = 0.1        | Keep multiplaying by x10
        Learing Rate = 1          | or x3 ...
        ...

     - Then choose the learning rate that gives the learning curve that
       'deacrease fast and continous'.

===[ Model: Polynomial Regression ]=============================================
* 'Polynomial Regression' is a type of regression analysis where the 
  relationship between the 'independent variable(x)' and the 'dependent'
  'variable (y)' is modeled as an nth-degree polynomial

  > [ Formula: ]
    
    [ Y-hat = a*X + b*X^2 + c*X^3 + ... + alpha ] 

  - It still considered a 'linear model', not because of the curve but because
    it's "linear in the coefficients".

  # NOTE:=======================================================================
  # - Polynomial regression transforms the original input features into
  #   'polynomial terms' (That what is called feature engineering).
  #   * Original Feature: 'X'
  #   * Transformed features: X, X^2, X^3, ..., X^n
  # - These nea features are then used in standard linear regression model to
  #   find the best-fitting curve.
  # ============================================================================

  > [ Things to Watch out For ]
    - 'Overfitting': High-degree polynomials can fit training data too colsely,  
      hurting generalization.
    - 'Extrapolation Risk': Polynomial curves can behave wildly outside the data
       range 
    - 'Scaling': It is a good idea to normalize or standardize input features  
      when using high-degree terms.

  > [ Linear Regression VS Polynomial Regression ]
  _____________________________________________________________________________
  | Aspect                 | Linear Regression | Polynomial Regression        |
  |------------------------|-------------------|------------------------------|
  |-Equation form          |-Y = ax + b        |-Y = aX + cX^2 + ...+ b       |
  |-Fit shape              |-Straight line     |-Curved line (parabola,       |
  |                        |                   | cubic, etc.)                 |
  |-Handles non-linearity? |-❌ No             |-✅ Yes                       |
  |-Model complexity       |-Low               |- Higher (risk of overfitting |
  |                        |                   | if degree is too high)       |
  |________________________|___________________|______________________________|

# CONCLUSION:===================================================================
# - Polynomial regression is a powerful extension of linear regression that
#   capture non-linear relationships by transforming features into polynomial
#   terms, It offers flexibility but must be used carefully to avoid overfitting 
# ==============================================================================

===[ Feature Engineering: ]===
* Feature engineering  is the process of 'transforming raw data into meaningful'
  'inputs (features)' that improve the performance of a machine learning model.
  - It involves 'selecting', 'creating', 'modifying' , or 'encoding varibales' 
    (features) in a way that helps the model 'better understand the patterns'
    'in the data'.

  > [ Feature Engineering Technique ]
    1. Feature Selection: (disavantage: ignoring of features) 
       - Choosing the most relevant feature. 
       - Removing redundant or irrelevant features.
    2. Feature Transformation:
       - 'Scaling': Normalize or standardize features 
       - 'Encoding': Convert categorical varibales => Numerical form 
    3. Feature Creation:
       - 'Combine existing' features (e.g S=weight * height) 
       - 'Extract information' (e.g extract "year" from a date)
    4. Handling Missing data:
       - Input missing values using 'mean', 'median', 'mode', or 'predictive'
         'models' 
    5. Dimensionality Reduction: 
       - 'Reduce the number of feature' while 'preserving' information (PCA, 
         t-SNE) 

# CONCLUSION:===================================================================
# - Feature engineering is the 'art and science' of turning raw data into useful
#   input for machine learning.
# - It can dramatically affect model performance and is often more impactful 
#   than tweaking algorithms themselves.
# - 'Data cleaning' prepares the data for modeling, 'Feature engineering' makes
#   the data useful for the model.
# ==============================================================================

===[ Linear Regression VS Classification ]======================================
# REVISION:
# - Regression is a type of supervised learning used to predict 'continuous' 
#   'values' by modeling the relationship between input features and output
#   * Predicting house prices based on size, location ...

> [ Classification ]
  * It is a type of 'supervised learning' used to 'predict categorical labels' 
    by learning patterns in the data that separate different 'classes'
    . Ex: Predicting whether an email is 'spam' or 'not spam'

  # NOTE:=======================================================================
  # Regression     => Predict Numbers (e.g price, revenue, ...) 
  # Classification => Predict categories (e.g pass/fail, ...) 
  # ============================================================================

# ERROR:========================================================================
# - While linear regression is meant for regression (predicting continous value) 
#   , It can be used for 'binary classification' as a simple baseline model, but 
#   It is generally not recommended.
# - You can use 'logistic regression' or 'other classification algorithms 
#   (e.g, decision trees, SVMS, random forests) instead
# ==============================================================================

===[ Logistic Regression: ]=====================================================
* It is a 'classification algorithm', not a regression algorithm (despite
  the name), It is used to 'predict the probability' that a given input belongs
  to a 'particular class', typically in 'binary classification' (e.g., yes/no,
  spam/not spam, 0/1). 

  > [ Formula: ]
    
    => [ Sigmoid (Z) = 1 / 1 + E^-Z ]

      - 0 < g(Z) < 1 
      - Z = f(a->, b) = a-> * x-> + b 
   
# INFO:=========================================================================
# - 'The sigmoid function' is a mathematical function that maps any real-valued
#   number into a range between '0 and 1'. It is commonly used in machine
#   learning, especially in classification tasks.
# > [ Formula: ]
#               1 
#     σ(x) = -------
#           1 + e^-x
#
#     - x: is the input
#     - e: Aulier's number 2.78 .. 

    => [ fa->, b(x->) = 1 / 1 + e^(a-> * x-> + b) ]
        g(fa->,b(x)) => g(a-> . x + b)  

      => g(...): is the sigmoid function 

                      1-|
                        |           *   * * *
                        |        *
                        |     *
        -0.5-         * | *  
                  *     |
               *        |
             *          |
    * * * *             |
    --------------------|----------------------> x
                        0

    - 0 < Ouput value < 1, means the probality that 'output value' is 1,
      givin input 'x->', parameters 'a->, b'
    - Example: F(x->) = 0.7: 'probalitiy of 70% that y is 1'
    - Fa->, b(X->) = P(y = 1|x->:w->,b): 'the probality that y is 1 givin input'
      'x->, parameters a->, b'

  # NOTE:=======================================================================
  # e: is the natural language of calculas (is the math of rate of change and
  # growth and areas)

> [ Auler's Number: ]

    => f(x) = (1 + 1 / n)^n   <|>  e = 1 + 1/1! + 1/2! + 1/3! + 1/4! + ..., etc 

  [   lim(n -> inf) (1 + 1/n)^n = e   ]


===[ Decision Boundary: ]===
* The 'decision boundary' is a concept used in 'classification problems' in 
  machine learning, it refers to the surface (or line in 2D) that 'separates'
  'different classes' predicted by a model.

                          [ Type of Decision Boundaries ]
                                        |
        |-------------------------------|-------------------------------|
        |                                                               |
  [ Linear classifiers ]                            [ Non-linear classifiers ]
* Produce 'straight lines' (or                    * Produce 'curved or'
  planes in higher dimensions)                      'irregular boundaries'
  . Logistic Regression
  . Linear SVM

# NOTE:=========================================================================
# - For logistic regression, decision boundary is where the predicted
#   probability is 0.5

> [ Why It matters: ]
  * Helps 'understand how your model makes predictions' 
  * Helps 'visualize and debug classification models'
  * Determines 'how well the model separates different classes' 
# NOTE:> Dataset are given in the form of the matrix (2D array table) 

- Since Logistic regression model = g(fa->, b(x->))  
                                  = 1 / 1 + e^-(a-> . x-> + b) 

- This rules are true:
  . g(x->) > 0.5 => 1 class is the probability | y-hat = 1 
  . g(x->) < 0.5 => 0 class is the probability | y-hat = 0 

  # NOTE: Y-hat is the predictted value that represent the classfication. 
  > [ Analysis: ]
    * Let is take the formula of logistic regression: 

        g(fa->,b(x->)) = 1 / 1 + e^-(a-> . x-> + b) 

    * At fa->,b(x->) = 0  ==> g(fa->, b(x->)) = 1 / 1 + e^0 = 0.5 
      - from this case we can simply tell:
      if (z = fa->,b(x->) > 0) 
          g(z) > 0.5 
      if (z = fa->,b(x->) > 0) 
          g(z) < 0.5

  # INFO:=======================================================================
  # - Descision boundary is where z = 0 
  #   |=> a-> . x-> + b = 0 (this teh threshold)
  #   |=> resuls a linear boundary that define my boundaries and split dataset
  #       into two classes.
  # - This type of classification is called linear decision boundaries. 


# NOTE:========================================================================= 
# - The sigmoid function transforms the output of the linear model into a bunded
#   range [0, 1]
# - sigmoid function does transform, map, wrap or squashes, (something like
#   normalization or feature scaling), This concept is called 'transforming into
#   a bounded range (in math)' 
# - fa->, b(x->) = 0: defines the 'decision boundary', because it is where the
#   probability is exactly 50% 
# ==============================================================================

> [ Analogy: ]
  * Think of it like this:
    - f(x) = a * x + b is like a ruler, measuring how far a point is
      from the dividing wall. 
    - f(x) = 0 is the wall itself 
    - On one side -> class1: on the other -> class 0

# INFO:
# - The equation f(x) = 0, represents the intercetion part 
# - Type of intersection parts:
#   . 2D => point
#   . 3D => line (intersection between two plans) in case of linear / non-linear
#           it can be curve or irregular function.

# NOTE:=========================================================================
# 1|_ understand f(x) gives a set of values that are the solution of f(x) = 0 
#     f(x) E |R => f(x) = 0 is the middle value f(x) > 0 or f(x) < 0, wich means
#     values above the line f(x) = 0 and values under the line f(x), this topic
#     has splited my space into to main categories one above the line and another
#     one under the line.
# 2|_ The boundaries equation just split the dataset into to main categories 
# 3|_ squatching those values under and above the the boundary equation 
# ==============================================================================
# 3|_ what is the quentity that help us measure the fitting of that line or
#     sigmoid function.
# 4|_ understand the quentity in a ghraphical way 

# QUESTION:[ If we take the same dataset, the fitting line in both cases
# linear regression and logistic classfication would be the same line ?]======== 
# - No, the are 'fitted using different objectives, which leads to different
#   lines' 
# ==============================================================================

===[ Cost function: ]===

# REVISION:=====================================================================
# - Convex function is the function that has the shape of 'bowl shape',
#   (e.g, cost function, x^2, ...) 
# - Logistic regression mode:
#                          1
#   g(fa->, b(x->)) = ------------ 
#                       1 + e^fa->,b(x->)
#   . a->: Controls the 'slop' or 'steepness' of the sigmoid curve. 
#   . b (bias): shifts the sigmoid 'left or right' and controls the 'threshold' 
#     or 'location' of the decision boundary.

* If we applied the 'mean squared error' on logistic regression model. The cost
  function won't be a "convex function" 

  > [ Example: ]

    |
    | *                            *
    |  *     *           *        * 
    |     *    *       *   *    * 
    | local min  *    *       * 
    |               *       local min 
    |           global min
    |--------------------------------

  - In this case the gradient desecnt won't be able to find the global min 
    if the local min is found.

  > [ Loss Function: ]
    * The loss function tells the model 'how far off' its prediction is:
      => lower is better. 
    - It simply tells the model how "wrong it is". 
      _______________________________________________________________
      | Model Type                | Loss Function                   |
      |---------------------------|---------------------------------|
      |-Regression                |-Mean Squared Error (MSE)        |
      |-Binary classification     |-Binary Cross-Entropy (Log Loss) |
      |-Multiclass classification |-Categorical Cross-Entropy       |
      |---------------------------|---------------------------------|

    * In the case of linear regression the loss function 
        [ L = sum(i->n)(yi-hat - yi)^2 ] 

    * In the case of logistic regression is called 'Binary Cross-Entropy'
      - It does use two functions on different intervals:

        /-----------------------------------------------
       | -log(fa->,b(x->))                  |=> if y = 1
    => |
       | -log(1 - fa->,b(x->))              |=> if y = 0
        \-----------------------------------------------

# QUESTION:[ Why applying or wrapping f(x->) by log(x) | function Composition? ] 
# * Function composition is to 'combine two or more functions' so that the ouput
#   of one becomes the input of another.
#   This allows you to build 'complex transformations' from simpler onces and
#   model 'multi-step' process mathematically. 
# * Applyting the logarithm function to another function expression is a common
#   technique in 'mathematics', 'statistics', and 'machine learning' and serves
#   several powerful purposes: 
# 1. Simplifies Multiplication into Addition: 
#     log(a * b) = log(a) + log(b)
# 2. Turns Exponentials grwoth into linear growth 
#    log(e^x) = x
# 3. Makes functions Easier to Optimize 
#    . Log transforms often 'smooth' curves and convexify loss function
# 4. Compress Scale (Handles Large Ranges) 
#    Ex: log(1) = 0, log(10) = 1, log(1000) = 3 
# 5. Interpretable Grwoth (int % terms)

- We already know that '0 < g(fa->, b(x->)) < 1', when we 'applied logarithm'
    on the g(z) probabilty value of class '1' givin by the 'sigmoid function'. 

> [ Analogy: -log(y-hat) <=> Think of logarithms as a "Surprize meter"]
  * It quantifies 'how surprised' the model is when the true label is 1.
  _______________________________________________________________________________
  | Prediction (y-hat)           | -log(y-hat) | Interpretation                 |
  |------------------------------|-------------|--------------------------------|
  | 0.99 (very confident, right) | ≈ 0.01      | Not surprised — low penalty ✅ |
  | 0.8 (pretty confident)       | ≈ 0.22      | Mildly surprised 😐            |
  | 0.5 (uncertain)              | ≈ 0.69      | Not confident — medium penalty |
  | 0.1 (confident but wrong)    | ≈ 2.30      | Very surprised — big penalty ❌|
  | 0.01 (very wrong)            | ≈ 4.60      | Shocked — huge penalty 🔥      |
  |______________________________|_____________|________________________________|
  - The scale that are used to make interpretation  
  _________________________________________________
  | Log Loss Value | Interpretation               |
  |----------------|------------------------------|
  | ~0.0 – 0.2     | Very confident and correct ✅|
  | ~0.3 – 0.7     | Uncertain prediction 😐      |
  | ~1.0 – 2.0     | Confident but wrong ❌       |
  | > 3.0          | Very confident and wrong ❌🔥|
  |________________|______________________________|

> [ Loss function: simplied form ] 

1. coding style
  L(fa->,b(x->), y-hat) = (y == 1) * -log(f(x->)) + (y == 0) * -log(1 - f(x->)) 

2. math style
  [ L(fa->,b(x->), y-hat) = y * -log(f(x->)) + (y - 1) * -log(1 - f(x->)) ] 


  > [ Cost function: ]
    * Ja->, b = sum(i = 1|-> m)(L(f(x), y-hat)) / m 
    _________________________________________________________________
    [                                                               ]
    [   ja->, b = sum(-y*log(f(x->) - (y-1)*log(1 - f(x)) / m       ]
    [           = -(1/m) * sum(ylog(f(x->)) - (y-1)*log(1-f(x))))   ]
    [_______________________________________________________________]

    # NOTE:=======================================================================
    # - The cost function is simple know, like the one in linear regression model.
    # ============================================================================

===[ Overfitting & Underfitting ]===============================================

===[ Overfitting: ]===
* Overfitting occures when a machine 'learning model learns not only th'
  'underlaying patterns' in the training data but also the 'noise and outliers',
  this leads the model to perform very well on the training data but
  'poorly on new, unseen data'

> [ Causes of Overfitting: ]
    1. 'Too Complex models': using models with too many parameters.   
    2. 'Insufficient Training Data': Small datasets can cause the model to
      memorize rather than generalize. 
    3. 'Too Many Training Epochs': Training for too long can cause the model
      to adapt too closely to the training data.
    4. 'Noisy Data': If the training data contains a lot fo 'noise or errors' 
    , the model may learn those instead of general trands

> [ Consequences of Overfitting: ]
  * 'Poor Generalization': the model performs well on training data but fails 
      to predict accurately on validation or test data
    * 'High Variance': Small changes in the input lead to large changes in
      the output.  
    * 'Unreliable Predictions': The model becomes less useful in real-world
      scenarios. 

  > [ Preventing Overfittiong (high varience): ]
    1. 'Simplify the model': use fewer parameters or a less complex algorithm. 
       => You can minimize the number of input featuresfor example
          (feature selection, take a subset instead of the dataset).
    2. 'Collect more Training Data': increasing the dataset size helps the model 
      generalize better.
    2. 'Regularization': 
        . 'L1/L2 Regularization': Penalize large weights. 
        . 'Dropout': Randomly drop neurons during training (in neural networks) 
    4. 'Early Stopping': Stop training when the validation preformance starts
       to degrade. 
    5. 'Cross-Validation' 
    6. 'Data augmentation': creation in feature engineering

> [ Regularization: ]
  * Changing the paramters of input features without eleminating the features  
    we can simply say 'we change the weight of input feature'

" The goal of regularization is to 'penalize model complexity' by discouraging"
"overly complex models with large weights, By doing so, it helps the model to"
"generalize better to new, unseen data"

  # INFO:===================================================
  # - Penalize: (verb) to cause someone a disadvantage.
  #   > Ex: The presetn tax system penlizes poor people. 
  # ========================================================

> [ Modified cost function: ]

  - Loss function in case of L1 regularization (lasso).
      [ Loss = Original Loss + lambda * sum(wi^2) ]
              --------------   --------------------
                'MSE term'    'Regularization term'

      # INFO:===================================================================
      # - λ (lambda) scales the penalty on the weights, and smaller weights tend 
      #   to produce smoother curves (especially in linear and polynomial models)
      # - “The weights are scaled by lambda, is that why the curve stays smooth”
      # - Without Regularization (lambda = 0): 
      #   . The model will try to 'perfectly fit' the training data.
      #   . This can lead to 'large weights', especially in high-degree
      #     polynomials or complex models. 
      #   . Result: the curve 'wiggles' through every data point -> 'not smooth'
      #     -> 'overfittiong'
      # - Wit regularization (lambda > 0):
      #   . The model is 'penalized' for large weights. 
      #   . To 'minimize loss', it prefers 'smaller weights' even if the error  
      #     on training data is slightly higher.
      #   . Resul: the fitted curve is 'smoother', with
      #     'fewer wild oscillations'  

      - 'Mean squared Term': it does minimize the 'residuals' for the making 
                             the best fittiong.
      - 'Regularization term': try to keeps 'Wi' wieghts too small 
      - 'lambda': Is the 'regular parameter', the ai engineer is the one that
                  select its value > 0, It balances both goals.

# QUESTION:===================================================================== 
# * Why not just manually scale the weights to be smaller and then use the
#   original loss (e.g MSE) ? Why do we need to change the loss function 
#   itself ?
# SOLUTION:=====================================================================
# - You want the training process to learn both: 
#   . How to 'minimize prediction error'
#   . How to avoid complexity ()
#  > You do this by creating 'a single loss function' that combines both goals:
#    [ Loss = MSE + λ⋅Penalty ]
#   ... This way, the optimizer balances both during training, not as 
#       post-processing step.
#  > [ Analogy: ]
#   * Imagine teaching a robot to walk:
#     . Without regularization: just tell it to walk fast (minimize time) 
#     . With regularization: you also penalize steps that are too wide 
#       (risk of failing).
#   * If you don't 'build that penalty into its goal function', it won't
#     learn safe walking, It will just go fast and fall over.
# CONCLUSION:=================================================================== 
# - Wahed a, b ghadi i3tiwni min cost function, ms had l min ghadi i3tini
#   wahed l model li t3alem bzff, o hna fin endi l mochkil l model makay3tinich
#   'better generalization, key 3tini poor generalization' lhal howa dik l min
#   nziid elih wahed term li ghadi ykhalini newssal l nefss l min walakin
#   bi w-> and b kbar mn l fi lcase lowla.
# - o had lqadiya katkhali l model dyali t3alem walkin endi wahed marge dyal
#   error o hadchii howa li kaykhali l model dyali endo 'better generalization'
#   or unseen data.
# - 'Regularization slightly increase training' on purpose to achieve a much
#   'lower test MSE' making the model more reliable on unseen data
# QUESTION:[ Why can't we just add a fixed value 'lambda' to cost function to 
# increase the error margin and avoid overfittiong ?]===========================
# - We can't just add a constant to the loss λ function because it has no 
#   effect on the optimization process, it does not change the model,
#   the weights, or the predictions.
#   (Constant value, it is derivative is 0, it will not effect the new weights
#   and bias in using the gradient descent algorithm)
# - Regularization must 'depend on the model  parameters' to actually influence
#   training and reduce overfitting.
# ==============================================================================

==[ Summary: ]==================================================================
  - Regularization is a core strategy for controlling model complexity, reducing
    overfittiong, and improving preformance on test data by modifying the loss
    function to penalize large or unnecessary weights.
  - Without regularization: 
    . You are finding the best fit to 'training data' (low bias, high variance)
  - With regularization: 
    . You are finding a balance, 'good fit' to training data, but with 'better' 
      'generalization' to unseen data (prediction).
  - Regularization "doesn't just increase the loss value, It changes how the"
    "loss is minimized", and that 'directly affects the final values of the'
    'weights and bias'
  > [ Analogy: ]
    * Imagine fitting a line to noisy (outlier) data.
      . Without regularization, you might bend the line too much to touch
        every point. 
      . With regularization, you allow some error but keep the line
        'reasonable and smooth', so it works better for future data. 
================================================================================

> [ Regularization With Gradient Descent: ]
  - Cost function with regularization:

    [----------------------------------------------------------------]
    [                  1                                             ]
    [  Jw->, b(x->) = ---- * (∑ (fw->,b(x->) - yi)^2 + λ * ∑ (Wi)^2) ]
    [                  2m                                            ]
    [----------------------------------------------------------------] 

  - Gradient Descent formual:

       /                   &
      | Wi = Wi - Alpha * ---- J(W->, b) 
   /|=|                    &Wi
   \|=|                  &
      | b = b - Alpha * ---- J(W->, b) 
       \                 &b

       /                     1                          lambda
      | Wi = Wi - Alpha * [ --- sum (f(x->) - y) * x] + ------ * wj ] 
   /|=|                      m                             m 
   \|=|                    1 
      | b = b - Alpha * [ --- sum(f(x->) - y) ]   => Still the same
       \                   m 

       /                        lambda              J(w->, b) 
      | Wi = Wi * (1 - alpha * -------) - ( alpha * ---------- ) 
   /|=|      ---------------------m---     -------------&w-------------- 
  |           Shrink 'wi' a little bit     The same case where lambda = 0 
   \|=|                    1 
      | b = b - Alpha * [ --- sum(f(x->) - y) ]   => Still the same
       \                   m 

