#  â €â €â €â €â €â €â €â €â €â¢€â£¤â£¦â£´â£¶â£¾â£¿â£¶â£¶â£¶â£¶â£¦â£¤â£„â €â €â €â €â €â €â €                                              
#  â €â €â €â €â €â €â €â¢ â¡¶â »â ›â Ÿâ ‹â ‰â €â ˆâ ¤â ´â ¶â ¶â¢¾â£¿â£¿â£¿â£·â£¦â „â €â €â €                ð““  ML_model ð“”           
#  â €â €â €â €â €â¢€â ”â ‹â €â €â ¤â ’â ’â¢²â €â €â €â¢€â£ â£¤â£¤â£¬â£½â£¿â£¿â£¿â£·â£„â €â €                                              
#  â €â €â €â£€â£Žâ¢¤â£¶â£¾â …â €â €â¢€â¡¤â â €â €â €â  â£„â£ˆâ¡™â »â¢¿â£¿â£¿â£¿â£¿â£¿â£¦â €       Dev:  oezzaou  oussama.ezzaou@gmail.com 
#  â¢€â ”â ‰â €â Šâ ¿â ¿â£¿â ‚â  â ¢â£¤â ¤â£¤â£¼â£¿â£¶â£¶â£¤â£â£»â£·â£¦â£â¡»â£¿â£¿â£¿â£¿â¡€                                              
#  â¢¾â£¾â£†â£¤â£¤â£„â¡€â €â €â €â €â €â €â €â ‰â¢»â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¡‡                                              
#  â €â ˆâ¢‹â¢¹â ‹â ‰â ™â¢¦â €â €â €â €â €â €â¢€â£¼â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¡‡       Created: 2025/05/12 08:13:45 by oezzaou
#  â €â €â €â ‘â €â €â €â ˆâ¡‡â €â €â €â €â£ â£¾â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â ‡       Updated: 2025/05/15 23:51:28 by oezzaou
#  â €â €â €â €â €â €â €â €â¡‡â €â €â¢€â£¾â£¿â£¿â ¿â Ÿâ ›â ‹â ›â¢¿â£¿â£¿â »â£¿â£¿â£¿â£¿â¡¿â €                                              
#  â €â €â €â €â €â €â €â¢€â ‡â €â¢ â£¿â£Ÿâ£­â£¤â£¶â£¦â£„â¡€â €â €â ˆâ »â €â ˜â£¿â£¿â£¿â ‡â €                                              
#  â €â €â €â €â €â ±â ¤â Šâ €â¢€â£¿â¡¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â €â €â €â €â €â €â ˜â£¿â â €â €                             ð“†©â™•ð“†ª      
#  â €â €â €â €â €â¡„â €â €â €â ˜â¢§â¡€â €â €â ¸â£¿â£¿â£¿â Ÿâ €â €â €â €â €â €â â ‹â €â €â €                     ð“„‚ oussama ezzaouð“†ƒ  
#  â €â €â €â €â €â ˜â „â£€â¡€â ¸â “â €â €â €â  â Ÿâ ‹â â €â €â €â €â €â €â €â €â €â €â €â €                                              

===[ Model: Linear Regression ]=================================================
* Linear regression: (easy) is used to 'model the relationship' between: 
  - One independent variable (push_swap: Size)
  - One independent variable (push_swap: Range)
    > It fits a 'stright' line through the 'data that best predict the output'.

  > [ Model Formula: ]

      f(x) = ax + b

    - The formula is called 'model' also in ML.
    - f(x): (y) is the target (y-hat is the estimated/predicted value)
    - x: Input feature 

    # NOTE:=====================================================================
    # - Training set is the data used for training the model.                  |
    # - The generted fuction is called sometimes 'hypothesis'.                 |
    # ==========================================================================

  > [ Example: ]
    - Predection of salary based on the experionce:
    _______________________________
    | Experience (x) | Salary (y) |
    |----------------|------------|
    | 1              |  30k      |
    | 2              |  35k      |
    | 3              |  40k      |
    |_4______________|__45k______|

    * The model my learn: 

      Salary = 5000 * Experience + 25000 

    * if input feature = 5
      Salary predected = 500 * 5 + 25000 = 50000

    > [ What it does ?: ]
      - It taks a data set of (x, y) data points.
      - Find the 'line for the function that minimize the error' between
        'predicted and actual value'.
      - After training it can predict a 'y-hat' for any input feature 'x' 

# TIP:========================================================================== 
# - Curve function gives sometimes more predictive input (The same case that   |
#   i have faced) in push swap Where a I got a curve function between size     |
#   and range and i have choosen to work with linear function instead to       |
#   simplify the calculation.                                                  |
# - Improving means find the function (model) that gives target inputs (y-hat) |
#   'predective output' closer to the 'actual output'.                         | 
# - Improving the model involves changing the value of 'a (slop)' and          | 
#   'b y-intercept'. That is the same what i have done to improve my function  |
#   in push_swap (a, b: are called parametters/coefficients/weights).          |
# - But how can we measure and make sure that the optimized function is the    |
#   suitable one ? (cost function).                                            | 
# ==============================================================================

  > [ Cost Function: Squared error cost function ]
  - In machine learning a cost function is 'mathematical formula' that measures
    how wrong model's prediction are. It simply tells the model how 'far off'
    from the true value (it measures the quality of fiting).
      * Low Cost: good predictions
      * High Cost: bad predictions

      (MSQ): stands for Mean Squared Error
               |-----------------------------------------------------|
      Formula: | J(a, b) = 1 / 2n * ensemble (i -> n) (Ypi - Yai)^2  | 
               |-----------------------------------------------------|

      # TIP: DO NOT forget to prove it mathimaticaly. 

      - Yai: is the actual/True output at 'i' 
      - Ypi: is the predictive output estemated by the model at 'i'. 
      - (Ypi - Yai) is called the 'error' or 'residual', distance
        between [actual/True output, predictive output], residual can
        be 'positive/negative'.
      - n: number of trained examples. 

# QUESTION:[ Why devided by 2n ?]=============================================== 
# - Dividing 'n' gives the **average** squared error across all training       |
#   examples truning it into a [ mean squared error ].                         |
# - Dividing by '2' is done for 'mathematical convenience', when you perform   |
#   'gradient descent' to minimize the cost function, you will compute its     |
#   derivative, The derivative of a squared term (e.g., (h âˆ’ y)^2) brings      |
#   down a factor of 2, which cancels out with the 1 / 2, 'This simplifies the |
#   gradient update formula'.                                                  | 
# CONCLUSION:                                                                  |
# - 1/n â†’ Makes the cost function an average per training example.             |
# - 1/2 â†’ Simplifies the math when taking derivatives.                         |
# ==============================================================================
