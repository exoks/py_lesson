#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚£¶‚£¥‚£∂‚£æ‚£ø‚£∂‚£∂‚£∂‚£∂‚£¶‚£§‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚°∂‚†ª‚†õ‚†ü‚†ã‚†â‚†Ä‚†à‚†§‚†¥‚†∂‚†∂‚¢æ‚£ø‚£ø‚£ø‚£∑‚£¶‚†Ñ‚†Ä‚†Ä‚†Ä                ìêì  train.py ìêî           
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†î‚†ã‚†Ä‚†Ä‚†§‚†í‚†í‚¢≤‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚£§‚£§‚£¨‚£Ω‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†Ä‚†Ä
#  ‚†Ä‚†Ä‚†Ä‚£Ä‚£é‚¢§‚£∂‚£æ‚†Ö‚†Ä‚†Ä‚¢Ä‚°§‚†è‚†Ä‚†Ä‚†Ä‚††‚£Ñ‚£à‚°ô‚†ª‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£¶‚†Ä       Eng: oezzaou <oussama.ezzaou@gmail.com>
#  ‚¢Ä‚†î‚†â‚†Ä‚†ä‚†ø‚†ø‚£ø‚†Ç‚††‚†¢‚£§‚†§‚£§‚£º‚£ø‚£∂‚£∂‚£§‚£ù‚£ª‚£∑‚£¶‚£ç‚°ª‚£ø‚£ø‚£ø‚£ø‚°Ä
#  ‚¢æ‚£æ‚£Ü‚£§‚£§‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚¢ª‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á
#  ‚†Ä‚†à‚¢ã‚¢π‚†ã‚†â‚†ô‚¢¶‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£º‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°á       Created: 2025/07/24 16:43:38 by oezzaou
#  ‚†Ä‚†Ä‚†Ä‚†ë‚†Ä‚†Ä‚†Ä‚†à‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†á       Updated: 2025/08/28 15:42:47 by oezzaou
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚¢Ä‚£æ‚£ø‚£ø‚†ø‚†ü‚†õ‚†ã‚†õ‚¢ø‚£ø‚£ø‚†ª‚£ø‚£ø‚£ø‚£ø‚°ø‚†Ä
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†á‚†Ä‚¢†‚£ø‚£ü‚£≠‚£§‚£∂‚£¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†à‚†ª‚†Ä‚†ò‚£ø‚£ø‚£ø‚†á‚†Ä
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†±‚†§‚†ä‚†Ä‚¢Ä‚£ø‚°ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚£ø‚†è‚†Ä‚†Ä                             ìÜ©‚ôïìÜ™
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ñ‚†Ä‚†Ä‚†Ä‚†ò‚¢ß‚°Ä‚†Ä‚†Ä‚†∏‚£ø‚£ø‚£ø‚†ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ê‚†ã‚†Ä‚†Ä‚†Ä                     ìÑÇ oussama ezzaouìÜÉ
#  ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚†Ñ‚£Ä‚°Ä‚†∏‚†ì‚†Ä‚†Ä‚†Ä‚††‚†ü‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä


# ===[ Imports: ]==============================================================
import data_loader
import preprocessing
from utils.logger import getLogger
import model as mod
from evaluate import evaluate_model


# ===[ main: ]=================================================================
def main():
    # 1. Loading the raw dataset
    data_raw = data_loader.load_raw_data()
    # 2. Data Preprocessing
    data = preprocessing.preprocess_data(data_raw)
    # 3. Save processed data
    data_loader.save_processed_data(data)
    # 4. Train-Test Split
    train_set, test_set = data_loader.train_test_split(data, 'Close', period=7)
    # 5. build the model
    model = mod.build_model(train_set, params=None)
    # 6. evalute the model
    evaluate_model(model, train_set, test_set, plot=True)

    # INFO:-------------------------------------------------------
    # the data is recorded daily, try monthly average
    # logger.debug("=================[data head]==================")
    # print(data.resample('ME').mean().head())
    # logger.debug("==============================================")


if __name__ == '__main__':
    main()


# ml-project/
# ‚îú‚îÄ‚îÄ data/
# ‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # Original, immutable data dump
# ‚îÇ   ‚îú‚îÄ‚îÄ processed/            # Cleaned data for modeling
# ‚îÇ   ‚îî‚îÄ‚îÄ external/             # Any 3rd-party or API data
# ‚îú‚îÄ‚îÄ notebooks/                # Jupyter notebooks for exploration & prototyping
# ‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb          # You do your initial data exploration here
# |   |                           (visualizations, correlations, missing values,
# |   |                           etc)
# ‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
# ‚îÇ   ‚îî‚îÄ‚îÄ 03_modeling.ipynb
# ‚îú‚îÄ‚îÄ src/                      # Core Python source code
# ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
# ‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Global config variables
# ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py        # Load and save data
# ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py      # Feature engineering, data cleaning
# ‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Model training
# ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # Evaluation metrics and visualization
# ‚îÇ   ‚îî‚îÄ‚îÄ model.py              # Model class, pipelines
# ‚îú‚îÄ‚îÄ models/                   # Trained model binaries (e.g., .pkl, .h5)
# ‚îÇ   ‚îî‚îÄ‚îÄ final_model.pkl
# ‚îú‚îÄ‚îÄ reports/                  # Results, plots, performance metrics
# ‚îÇ   ‚îú‚îÄ‚îÄ figures/
# ‚îÇ   ‚îî‚îÄ‚îÄ metrics.txt
# ‚îú‚îÄ‚îÄ tests/                    # Unit and integration tests
# ‚îÇ   ‚îî‚îÄ‚îÄ test_model.py
# ‚îú‚îÄ‚îÄ scripts/                  # CLI scripts (optional)
# ‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline.py
# ‚îú‚îÄ‚îÄ .gitignore
# ‚îú‚îÄ‚îÄ README.md
# ‚îú‚îÄ‚îÄ requirements.txt
# ‚îú‚îÄ‚îÄ setup.py                  # Optional for packaging
# ‚îî‚îÄ‚îÄ LICENSE


# INFO:------------------------------------------------------------------------
# > 'train.py': The 'conductor' of the orchestar, it does not do everything
#   itself, but 'corrdinates': data, model preprocessing, evaluation
# > 'model.py' is to 'define and return your machine learning model' or
#   'pipeline'.
#   - It actes like a factory: you give it parameters (from 'config.py'
#     and it gives you back a ready-to-train model object
# > 'config.py': This file stores all the 'global settings', 'parameters', 'and
#   file paths' that your project needs.
# -----------------------------------------------------------------------------
